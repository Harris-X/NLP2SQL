### model
model_name_or_path: output/qwen3_coder_30b_dpo_merged
trust_remote_code: true
template: qwen3_nothink
flash_attn: fa2
enable_liger_kernel: true

### method
stage: sft
do_train: true
finetuning_type: lora
lora_rank: 32
# 在 "all" 上打 LoRA，包含 q_proj,v_proj 等所有线性层
lora_target: all

### dataset
dataset: sft_text2sql
cutoff_len: 65536
max_samples: 10000  # 0 表示用完整数据集
preprocessing_num_workers: 16
dataloader_num_workers: 4

### train
output_dir: saves/qwen3-coder-30b/lora/dpo_all_from_qk
per_device_train_batch_size: 1
gradient_accumulation_steps: 2
num_train_epochs: 7
learning_rate: 1e-4
lr_scheduler_type: cosine
warmup_ratio: 0.05
bf16: true
logging_steps: 10
save_steps: 500
ddp_timeout: 180000
resume_from_checkpoint: null
ddp_find_unused_parameters: true
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false
